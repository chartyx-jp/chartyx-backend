import numpy as np
import pandas as pd
from tqdm import tqdm
from apps.stocks.services.yahoo_fetcher import ParquetHandler
from apps.ai.features.base import FeatureGeneratorBase
from apps.common.app_initializer import DjangoAppInitializer
from django.conf import settings


class BasicFeatureGeneratorV4(FeatureGeneratorBase, DjangoAppInitializer):
    CATEGORY_BINS = [
        (0, 524),
        (524, 1020),
        (1020, 1923),
        (1923, 5000),
        (5000, 10000),
        (10000, 50000),
        (50000, float('inf'))
    ]
    CATEGORY_LABELS = [
        '0ã€œ524å††',
        '524ã€œ1020å††',
        '1020ã€œ1923å††',
        '1923ã€œ5000å††',
        '5000ã€œ10000å††',
        '10000ã€œ50000å††',
        '50000å††ä»¥ä¸Š'
    ]

    def __init__(self, *args, **kwargs) -> None:
        super().__init__(*args, **kwargs)

        self.__read_handler = ParquetHandler(directory=settings.RAW_DATA_DIR/"japan", batch_size=20)
        self.__write_handler = ParquetHandler(directory=settings.PROCESSED_DATA_DIR, batch_size=20)
        
    def make_transformed_data(self) -> None:
        """
        ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›ã—ã¦Parquetãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹ã€‚
        """
        for file in tqdm(self.__read_handler.files, desc="ãƒ‡ãƒ¼ã‚¿å¤‰æ›ä¸­", unit="ãƒ•ã‚¡ã‚¤ãƒ«"):
            try:
                df = pd.read_parquet(file)
                df_transformed = self.transform(df)
                df_transformed = self.drop_unused_columns(df=df_transformed)
                self.__write_handler.save(df_transformed,filename=file.name)
            except Exception as e:
                self.log.error(f"ãƒ‡ãƒ¼ã‚¿å¤‰æ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e},{file.name}å†…")
        self.log.info( "å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›ã—ã¦ä¿å­˜ã—ã¾ã—ãŸã€‚")
            
            
                

            


    def transform(self, df: pd.DataFrame) -> pd.DataFrame:
        df = df[["Date", "Open", "High", "Low", "Close", "Volume"]].copy()
        df = df[df["Open"].notna() & (df["Close"] != 0)]

        df["Date"] = pd.to_datetime(df["Date"])
        df.sort_values("Date", inplace=True)

        # logä¾¡æ ¼ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
        df["LogClose"] = np.log(df["Close"])
        df["Target"] = df["LogClose"].shift(-1) - df["LogClose"]

        # logãƒ™ãƒ¼ã‚¹ã®MAã¨ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        for window in [5, 20, 50, 200]:
            df[f"LogMA_{window}"] = df["LogClose"].rolling(window).mean()
            df[f"LogVolatility_{window}"] = df["LogClose"].rolling(window).std()
            df[f"Price_to_LogMA_{window}"] = df["LogClose"] - df[f"LogMA_{window}"]

        # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰ä¸Šãƒ»ä¸‹ãƒ»å¹…
        ma20 = df["LogMA_20"]
        std20 = df["LogClose"].rolling(20).std()
        df["LogBB_Upper"] = ma20 + 2 * std20
        df["LogBB_Lower"] = ma20 - 2 * std20
        df["LogBB_Width"] = df["LogBB_Upper"] - df["LogBB_Lower"]

        # 52é€±å®‰å€¤ãƒ»é«˜å€¤ï¼ˆlogã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
        df["Log52WeekLow"] = df["LogClose"].rolling(252).min()
        df["Log52WeekHigh"] = df["LogClose"].rolling(252).max()
        df["LogRange_to_High"] = df["Log52WeekHigh"] - df["LogClose"]
        df["LogRange_to_Low"] = df["LogClose"] - df["Log52WeekLow"]

        # å‡ºæ¥é«˜ç³»
        df["Volume_Change_1D"] = df["Volume"].pct_change(fill_method=None)
        df["Volume_Ratio"] = df["Volume"] / df["Volume"].rolling(5).mean().replace(0, np.nan)
        df["AverageVolume3M"] = df["Volume"].rolling(63).mean()
        df["Vol_Surge_5"] = (df["Volume_Ratio"] > 1.5).astype(int)
        df["Volume_to_AvgRatio"] = df["Volume"] / df["AverageVolume3M"]

        # RSI & ã‚¹ãƒˆãƒªãƒ¼ã‚¯
        delta = df["Close"].diff()
        gain = delta.where(delta > 0, 0.0)
        loss = -delta.where(delta < 0, 0.0)
        avg_gain = gain.rolling(14).mean()
        avg_loss = loss.rolling(14).mean()
        rs = avg_gain / avg_loss.replace(0, np.nan)
        df["RSI_14"] = 100 - (100 / (1 + rs))
        df["RSI_Trend"] = df["RSI_14"] - df["RSI_14"].shift(3)
        df["RSI_Over70"] = (df["RSI_14"] > 70).astype(int)
        df["RSI_Over70_Streak"] = df["RSI_Over70"] * (
            df["RSI_Over70"].groupby((df["RSI_Over70"] != df["RSI_Over70"].shift()).cumsum()).cumcount() + 1
        )

        # MACD
        ema12 = df["LogClose"].ewm(span=12, adjust=False).mean()
        ema26 = df["LogClose"].ewm(span=26, adjust=False).mean()
        df["MACD"] = ema12 - ema26
        df["MACD_Signal"] = df["MACD"].ewm(span=9, adjust=False).mean()
        df["MACD_Above0"] = (df["MACD"] > 0).astype(int)
        df["MACD_Above_0_Streak"] = df["MACD_Above0"] * (
            df["MACD_Above0"].groupby((df["MACD_Above0"] != df["MACD_Above0"].shift()).cumsum()).cumcount() + 1
        )

        # ãƒˆãƒ¬ãƒ³ãƒ‰ç³»ï¼ˆlogå·®åˆ†ï¼‰
        for lag in [1, 3, 5, 10, 20]:
            df[f"LogReturn_{lag}"] = df["LogClose"] - df["LogClose"].shift(lag)

        # ãƒ­ãƒ¼ã‚½ã‚¯è¶³ç³»
        df["CandleBody"] = (df["Close"] - df["Open"]).abs()
        df["UpperShadow"] = df["High"] - df[["Open", "Close"]].max(axis=1)
        df["LowerShadow"] = df[["Open", "Close"]].min(axis=1) - df["Low"]
        df["GapUpDown"] = df["Open"] - df["Close"].shift(1)
        df["IsBullish"] = (df["Close"] > df["Open"]).astype(int)
        df["IsBearish"] = (df["Close"] < df["Open"]).astype(int)

        # æ¯”ç‡ç³»
        df["Pct_Open_to_Close"] = (df["Close"] - df["Open"]) / df["Open"]
        df["Pct_High_to_Low"] = (df["High"] - df["Low"]) / df["Low"]
        df["Pct_Close_to_High"] = (df["High"] - df["Close"]) / df["Close"]
        df["Open_to_High"] = (df["High"] - df["Open"]) / df["Open"]
        df["Open_to_Low"] = (df["Open"] - df["Low"]) / df["Open"]
        df["Close_to_Open"] = (df["Close"] - df["Open"]) / df["Open"]
        df["Close_to_High"] = (df["High"] - df["Close"]) / df["High"]
        df["Close_to_Low"] = (df["Close"] - df["Low"]) / df["Low"]
        df["Range_Pct"] = (df["High"] - df["Low"]) / df["Open"]
        df["LogRange"] = np.log(df["High"]) - np.log(df["Low"])
        df["LogBody"] = np.log(df["Close"]) - np.log(df["Open"])

        # æ™‚ç³»åˆ—ç‰¹å¾´é‡ï¼ˆå¾ªç’°ï¼‰
        df["Month_sin"] = np.sin(2 * np.pi * df["Date"].dt.month / 12)
        df["Month_cos"] = np.cos(2 * np.pi * df["Date"].dt.month / 12)
        df["DOW_sin"] = np.sin(2 * np.pi * df["Date"].dt.dayofweek / 5)
        df["DOW_cos"] = np.cos(2 * np.pi * df["Date"].dt.dayofweek / 5)
        
        self.add_price_category(df, price_col='Close', category_col='price_category')
        
        df = df.drop(["Date", "Open", "High", "Low", "Close", "Volume"], axis=1)

        return df

    @staticmethod
    def split(df: pd.DataFrame, remove_zero_target: bool = True):
        if isinstance(df, pd.Series):
            df = pd.DataFrame([df])

        df = df.copy()
        initial_len = len(df)

        # Target æ¬ æã‚’é™¤å»
        df = df.dropna(subset=["Target"])
        after_target_len = len(df)
        print(f"{initial_len - after_target_len}è¡Œã®TARGETã«æ¬ æå€¤ãŒã‚ã‚Šã¾ã—ãŸ")

        # TargetãŒ0ã«æ¥µã‚ã¦è¿‘ã„ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ï¼ˆå¤‰å‹•ãªã—ã¨ã—ã¦æ‰±ã†ï¼‰
        if remove_zero_target:
            threshold = 1e-4
            df = df[df["Target"].abs() > threshold]
            print(f"{after_target_len - len(df)}è¡Œã®TARGETãŒé–¾å€¤ä»¥ä¸‹ï¼ˆÂ±{threshold}ï¼‰ã ã£ãŸãŸã‚é™¤å¤–ã—ã¾ã—ãŸ")

        # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†é›¢ï¼ˆå…ƒã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’é™¤ãï¼‰
        drop_cols = ["Date", "Target", "Open", "High", "Low", "Close", "Volume"]
        X = df.drop(columns=drop_cols, errors="ignore")

        # Infé™¤å» + NaNé™¤å»
        X.replace([np.inf, -np.inf], np.nan, inplace=True)
        inf_nan_rows = X.isna().any(axis=1).sum()
        X.dropna(inplace=True)
        print(f"{inf_nan_rows} è¡Œã®INFã¾ãŸã¯NaNãŒã‚ã‚Šã¾ã—ãŸã€€ï¼ˆDROPï¼‰")

        y = df.loc[X.index, "Target"]

        print(f"æœ€çµ‚ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X)} è¡Œ, {X.shape[1]} ç‰¹å¾´é‡")
        return X, y

    def drop_unused_columns(self, df: pd.DataFrame,threshold:float = 1e-4) -> pd.DataFrame:
        """
        ä¸æ•´å€¤ã‚’å‰Šé™¤ã™ã‚‹ã€‚
        """
        if isinstance(df, pd.Series):
            df = pd.DataFrame([df])
        df = df.dropna(subset=["Target"])

        # TargetãŒ0ã«æ¥µã‚ã¦è¿‘ã„ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ï¼ˆå¤‰å‹•ãªã—ã¨ã—ã¦æ‰±ã†ï¼‰
        df = df[df["Target"].abs() > threshold]

        df.replace([np.inf, -np.inf], np.nan, inplace=True)
        df.dropna(inplace=True)

        return df


    def get_week_of_month(self, date):
        first_day = date.replace(day=1)
        dom = date.day
        adjusted_dom = dom + first_day.weekday()  # æœˆæ›œèµ·ç‚¹ï¼ˆweekday=0ï¼‰
        return int(np.ceil(adjusted_dom / 7.0))
    
    
    @classmethod
    def get_price_category_number(cls, price):
        for i, (low, high) in enumerate(cls.CATEGORY_BINS):
            if low <= price < high:
                return i + 1  # 1å§‹ã¾ã‚Š
        return len(cls.CATEGORY_BINS)

    @classmethod
    def get_price_category_label(cls, price):
        for i, (low, high) in enumerate(cls.CATEGORY_BINS):
            if low <= price < high:
                return cls.CATEGORY_LABELS[i]
        return cls.CATEGORY_LABELS[-1]

    def add_price_category(self, df, price_col='Close', category_col='price_category'):
        """
        æŒ‡å®šã•ã‚ŒãŸDataFrameã«ä¾¡æ ¼ã‚«ãƒ†ã‚´ãƒªç•ªå·åˆ—ï¼ˆ1,2,...ï¼‰ã¨ã‚«ãƒ†ã‚´ãƒªãƒ©ãƒ™ãƒ«åˆ—ã‚’è¿½åŠ 
        """
        df[category_col] = df[price_col].apply(self.get_price_category_number)
        return df
    
    def plot_close_distribution(self, threshold: float = 1e-4):
        """
        Plot distribution of valid Close prices in Â¥1000 price bins.
        """
        from collections import Counter
        import numpy as np
        import matplotlib.pyplot as plt

        counter = Counter()
        total_count = 0
        # price_bins = np.arange(-0.1, 0.1 + 0.01, 0.01)  # -10%ã€œ+10%ã‚’1%åˆ»ã¿ã§ LOGå·®åˆ†

        price_bins = np.arange(0, 100000, 1000)

        for df_transformed in self.__read_handler.load_each(suffix=".parquet"):
            df_transformed = self.transform(df_transformed)
            df_transformed = self.drop_unused_columns(df=df_transformed)
            # X,y = self.split(df_transformed, remove_zero_target=True)
            # valid_close = y

            valid_close = df_transformed[
                df_transformed["Close"] > 0
                # df_transformed["Target"].notna() &
                # (df_transformed["Target"].abs() != 0) &
                # (df_transformed["Close"] > 0)
            ]["Close"]

            bin_indices = np.digitize(valid_close, price_bins, right=False)
            for b in bin_indices:
                counter[b] += 1
            total_count += len(valid_close)

        # ãƒ©ãƒ™ãƒ«ã¨å‰²åˆä½œæˆï¼ˆindex errorå›é¿ï¼‰
        labels = []
        percentages = []
        bin_counts = []  # â† ä»¶æ•°ã‚‚è¨˜éŒ²ã™ã‚‹
        print(sorted(counter.keys()))
        for i in sorted(counter.keys()):
            if i < len(price_bins):
                label = f"{price_bins[i - 1]}â€“{price_bins[i]}"
            else:
                label = f"{price_bins[-1]}+"
            labels.append(label)
            
            count = counter[i]
            percentage = count / total_count * 100

            percentages.append(percentage)
            bin_counts.append(count)  # ä»¶æ•°ä¿å­˜

            # ä»¶æ•°ã¨å‰²åˆã‚’ãƒ­ã‚°å‡ºåŠ›
            print(f"{label}: {count}ä»¶ ({percentage:.4f}%)")
        print(f"å…¨ä½“ä»¶æ•°{total_count}")

        # æç”»
        plt.figure(figsize=(12, 5))

        # æ£’ã‚°ãƒ©ãƒ•ï¼ˆå‰²åˆï¼‰
        bars = plt.bar(labels, percentages, label='Percentage by Price Range', color='skyblue', edgecolor='black')

        # æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ï¼ˆæ»‘ã‚‰ã‹ã«å¤‰åŒ–ã‚’è¦‹ã‚‹ï¼‰
        plt.plot(range(len(labels)), percentages, color='orange', marker='o', linestyle='-', linewidth=1.5, markersize=4, label='Trend Line')

        # Xè»¸ãƒ©ãƒ™ãƒ«é–“å¼•ãï¼ˆé•·ã™ãé˜²æ­¢ï¼‰
        plt.xticks(
            ticks=np.arange(len(labels))[::2],
            labels=[labels[i] for i in range(len(labels))][::2],
            rotation=60,
            fontsize=8
        )

        plt.title("Distribution of Stocks by Price Range (per Â¥1000)")
        plt.ylabel("Percentage (%)")
        plt.legend()
        plt.tight_layout()
        plt.show()


    def analyze_close_distribution(self, n_bins=50):
        """
        æ ªä¾¡ã®Closeåˆ†å¸ƒã‚’ã€ç®±ã²ã’å›³ã¨ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã§å¯è¦–åŒ–ã€‚
        ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ãƒ»ç®±ã²ã’å›³ã®xè»¸ç¯„å›²ã¯ã€ŒLOWERï½UPPERã®ä¸­ã®å®Ÿãƒ‡ãƒ¼ã‚¿MINï½MAXã€ã«é™å®šã€‚
        ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®ãƒ“ãƒ³æ•°ã‚‚n_binsã§ç´°ã‹ãèª¿æ•´å¯èƒ½ã€‚
        """
        import numpy as np
        import pandas as pd
        import matplotlib.pyplot as plt
        import seaborn as sns

        # ã™ã¹ã¦ã®Closeä¾¡æ ¼ã‚’åé›†
        all_close = []
        try:
            for df in self.__read_handler.load_each(suffix=".parquet"):
                df = self.transform(df)
                valid = self.drop_unused_columns(df=df)
                all_close.extend(valid["Close"].dropna().tolist())
        except AttributeError:
            print("Warning: '__read_handler' not found. Using dummy data for demonstration.")
            dummy_data = np.random.normal(loc=700, scale=100, size=5000).tolist() + \
                        np.random.normal(loc=1200, scale=50, size=100).tolist() + \
                        np.random.normal(loc=300, scale=30, size=100).tolist() + \
                        [np.nan]*50 + [-10]*20
            all_close.extend(dummy_data)

        close = pd.Series(all_close)
        close = close[close > 0]  # 0ä»¥ä¸‹é™¤å¤–

        if close.empty:
            print("Error: No valid Close prices found after filtering.")
            return

        # å››åˆ†ä½æ•°ãƒ»IQRãƒ»ç†è«–ã²ã’
        q1 = close.quantile(0.25)
        q3 = close.quantile(0.75)
        iqr = q3 - q1
        lower_whisker_boundary = q1 - 1.5 * iqr
        upper_whisker_boundary = q3 + 1.5 * iqr

        # 0æœªæº€ã«ãªã‚‰ãªã„ã‚ˆã†ã«èª¿æ•´ã—ã€LOWERï½UPPERå†…ã®å®Ÿãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ½å‡º
        whisker_data = close[(close >= max(0, lower_whisker_boundary)) & (close <= upper_whisker_boundary)]
        if whisker_data.empty:
            min_in_range, max_in_range = q1, q3
        else:
            min_in_range, max_in_range = whisker_data.min(), whisker_data.max()

        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®ãƒ“ãƒ³å®šç¾©ï¼ˆMINï½MAXã§ç­‰é–“éš”ï¼‰
        bins_arr = np.linspace(min_in_range, max_in_range, n_bins + 1)

        # ãƒ“ãƒ³é›†è¨ˆ
        bin_labels = [f"{int(bins_arr[i])}-{int(bins_arr[i+1])}" for i in range(len(bins_arr) - 1)]
        bin_counts = pd.cut(whisker_data, bins=bins_arr, labels=bin_labels, include_lowest=True).value_counts().sort_index() # type: ignore

        median = close.median()
        mean = close.mean()

        # æç”»
        plt.figure(figsize=(14, 7))

        # 1. ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
        plt.subplot(1, 2, 1)
        sns.histplot(
            whisker_data, 
            bins=bins_arr, 
            color="skyblue", 
            edgecolor="black", 
            kde=False
        )
        plt.axvline(q1, color='green', linestyle='--', label=f'Q1 (25%): {q1:.1f}')
        plt.axvline(median, color='orange', linestyle='-', label=f'Median (50%): {median:.1f}')
        plt.axvline(q3, color='red', linestyle='--', label=f'Q3 (75%): {q3:.1f}')
        plt.axvline(mean, color='purple', linestyle=':', label=f'Mean: {mean:.1f}')
        plt.xlim(min_in_range, max_in_range)
        plt.title("Histogram of Close Prices (MIN-MAX of Whisker)")
        plt.xlabel("Close Price")
        plt.ylabel("Frequency")
        plt.legend()
        plt.grid(axis='y', linestyle='--', alpha=0.7)

        # 2. Boxplot
        plt.subplot(1, 2, 2)
        sns.boxplot(x=close, color="lightgreen")
        # ç›®è¦–ã—ã‚„ã™ãç¯„å›²ã‚‚MINï½MAX
        plt.axvline(min_in_range, color='blue', linestyle=':', label=f'MIN in Whisker: {min_in_range:.1f}')
        plt.axvline(max_in_range, color='blue', linestyle=':', label=f'MAX in Whisker: {max_in_range:.1f}')
        plt.axvline(median, color='orange', linestyle='-', label=f'Median (50%)')
        plt.text(median, plt.ylim()[1] * 0.05, "Median", ha='center', color='orange', weight='bold')
        plt.xlim(min_in_range, max_in_range)
        plt.title("Boxplot of Close Prices (MIN-MAX of Whisker Data)")
        plt.xlabel("Close Price")
        plt.legend()
        plt.grid(axis='x', linestyle='--', alpha=0.7)
        plt.tight_layout()
        plt.show()

        # ãƒ†ã‚­ã‚¹ãƒˆãƒ­ã‚°å‡ºåŠ›
        print("\nğŸ“¦ IQR Stats")
        print(f"Q1: {q1:.2f}, Q3: {q3:.2f}, IQR: {iqr:.2f}")
        print(f"Median: {median:.2f}, Mean: {mean:.2f}")
        print(f"Theoretical Lower Whisker (Q1 - 1.5*IQR): {lower_whisker_boundary:.2f}")
        print(f"Theoretical Upper Whisker (Q3 + 1.5*IQR): {upper_whisker_boundary:.2f}")
        print(f"MIN in Whisker (>=0): {min_in_range:.2f}")
        print(f"MAX in Whisker: {max_in_range:.2f}")
        print(f"\nğŸ”¹ Bin Counts within Whisker MIN-MAX:")
        print(bin_counts)
        
    def process_all_parquet_files(self, threshold=65000):
        """
        Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…¨ã¦è‡ªå‹•ã§ãƒã‚§ãƒƒã‚¯ã—ã€Closeã«é–¾å€¤ä»¥ä¸ŠãŒã‚ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å‡ºåŠ›ã€‚
        å‘¼ã³å‡ºã—ã®ã¿ã§å®Œçµã€‚ä½•ã‚‚è¿”ã•ãªã„ã€‚
        """

        for file_path in self.__read_handler.files:
            try:
                df = pd.read_parquet(file_path)
            except Exception as e:
                print(f"èª­ã¿è¾¼ã¿å¤±æ•—: {file_path}, error: {e}")
                continue

            if (df['Close'] >= threshold).any():
                print(f"ã‚¹ã‚­ãƒƒãƒ—: Closeã«{threshold}ä»¥ä¸Šã‚’æ¤œå‡º â†’ {file_path}")
                continue

            # ã“ã“ã«ã€Œé€šå¸¸ã®å‡¦ç†ã€ã‚’æ›¸ã
            # print(f"å‡¦ç†: {file_path}")

        print("å…¨ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

        
if __name__ == "__main__":
    generator = BasicFeatureGeneratorV4()
    # generator.plot_close_distribution(threshold=1e-4)
    # generator.analyze_close_distribution(n_bins=50)
    # generator.process_all_parquet_files(threshold=65000)
    generator.make_transformed_data()
    

